{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diyism/colab_kaldi2/blob/main/my_icefall_yes_no_dataset_recipe_with_CPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "#import os\n",
        "#print(os.path.realpath(\"__file__\"))\n",
        "#!cat /content/icefall/egs/yesno/ASR/tdnn/decode.py\n",
        "!ls -al /content/icefall/egs/yesno/ASR/tdnn/exp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lKrglcGRwTh",
        "outputId": "8c25961f-5c77-4348-c900-6eeac95fa689",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "ls: cannot access '/content/icefall/egs/yesno/ASR/tdnn/exp': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLcRRqz9RtJS"
      },
      "source": [
        "# Yesno recipe in icefall\n",
        "\n",
        "This notebook shows you how to setup the environment to use [icefall][icefall] for training and decoding.\n",
        "It also describes how to use a per-trained model to decode waves.\n",
        "\n",
        "\n",
        "We use the [yesno] dataset as an example.\n",
        "\n",
        "[icefall]: https://github.com/k2-fsa/icefall\n",
        "[yesno]: https://www.openslr.org/1/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8jMkYeDQUeY"
      },
      "source": [
        "## Environment setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AliAaueDNteG",
        "outputId": "5e36f611-bdf1-4e92-abf0-c72243d94cbf",
        "collapsed": true
      },
      "source": [
        "#1. Install PyTorch, torchaudio, k2\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torchaudio\n",
        "import torchaudio\n",
        "print(torchaudio.__version__)\n",
        "\n",
        "#the cuda version and torch version should match the upper printed verions\n",
        "!pip install -q k2==1.24.4.dev20240905+cuda12.1.torch2.4.1 -f https://k2-fsa.github.io/k2/cuda.html\n",
        "!python3 -m k2.version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.1+cu121\n",
            "2.4.1+cu121\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting environment information...\n",
            "\n",
            "k2 version: 1.24.4\n",
            "Build type: Release\n",
            "Git SHA1: cf664841c6d93e21e59b40aade84869b76c919c1\n",
            "Git date: Thu Sep 5 19:25:17 2024\n",
            "Cuda used to build k2: 12.1\n",
            "cuDNN used to build k2: \n",
            "Python version used to build k2: 3.10\n",
            "OS used to build k2: CentOS Linux release 7.9.2009 (Core)\n",
            "CMake version: 3.30.2\n",
            "GCC version: 9.3.1\n",
            "CMAKE_CUDA_FLAGS: -Wno-deprecated-gpu-targets -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_50,code=sm_50 -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_60,code=sm_60 -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_61,code=sm_61 -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_70,code=sm_70 -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_75,code=sm_75 -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_86,code=sm_86 -DONNX_NAMESPACE=onnx_c2 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_90,code=sm_90 -Xcudafe --diag_suppress=cc_clobber_ignored,--diag_suppress=field_without_dll_interface,--diag_suppress=base_class_has_different_dll_interface,--diag_suppress=dll_interface_conflict_none_assumed,--diag_suppress=dll_interface_conflict_dllexport_assumed,--diag_suppress=bad_friend_decl --expt-relaxed-constexpr --expt-extended-lambda -D_GLIBCXX_USE_CXX11_ABI=0 --compiler-options -Wall  --compiler-options -Wno-strict-overflow  --compiler-options -Wno-unknown-pragmas \n",
            "CMAKE_CXX_FLAGS:  -D_GLIBCXX_USE_CXX11_ABI=0 -Wno-unused-variable  -Wno-strict-overflow \n",
            "PyTorch version used to build k2: 2.4.1+cu121\n",
            "PyTorch is using Cuda: 12.1\n",
            "NVTX enabled: True\n",
            "With CUDA: True\n",
            "Disable debug: True\n",
            "Sync kernels : False\n",
            "Disable checks: False\n",
            "Max cpu memory allocate: 214748364800 bytes (or 200.0 GB)\n",
            "k2 abort: False\n",
            "__file__: /usr/local/lib/python3.10/dist-packages/k2/version/version.py\n",
            "_k2.__file__: /usr/local/lib/python3.10/dist-packages/_k2.cpython-310-x86_64-linux-gnu.so\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SsFZwCESWz_",
        "outputId": "b508163b-4fef-47ee-f0be-b7c28c721737"
      },
      "source": [
        "#2. install lhotse\n",
        "#Normally, we would use pip install lhotse. However, the yesno recipe is added recently and has not been released to PyPI yet,\n",
        "#so we install the latest unreleased version here.\n",
        "!pip install -q git+https://github.com/lhotse-speech/lhotse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for lhotse (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP4RZ31xTKzL",
        "outputId": "ed73b0d2-25ae-4396-94ee-6ca3f5d37dea"
      },
      "source": [
        "#3. install icefall\n",
        "#k2-icefall is a collection of Python scripts.You don't need to install it. What you need to do is to get its source code,\n",
        "#install its dependencies, and set the PYTHONPATH pointing to it.\n",
        "!git clone https://github.com/k2-fsa/icefall\n",
        "!pip install -q --upgrade onnxconverter-common\n",
        "!cd icefall && pip install -q -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'icefall' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeFyXWEOT4Mi"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqMH7ZLKT8jM"
      },
      "source": [
        "We have set up the environment. Now it is the time to prepare data for training and decoding.\n",
        "\n",
        "As we just said, `icefall` is a collection of Python scripts and we have to set up the `PYTHONPATH` variable to use it. Remember that `icefall` was downloaded to\n",
        "`/content/icefall`, so we use\n",
        "\n",
        "```\n",
        "export PYTHONPATH=/content/icefall:$PYTHONPATH\n",
        "```\n",
        "\n",
        "**HINT**: You can have several versions of `icefall` in your virtual environemnt. To switch to a specific version of `icefall`, just change the `PYTHONPATH` environment variable."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To remove the following warning message\n",
        "# 2023-07-27 05:03:07.156920: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
        "! pip uninstall -y tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YQUEXWruxFu",
        "outputId": "535c0c0b-b885-4225-d3f9-4dc968f254e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.17.0\n",
            "Uninstalling tensorflow-2.17.0:\n",
            "  Successfully uninstalled tensorflow-2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzyw8VyfUjUB",
        "outputId": "874e9574-1575-40a9-c933-8da2433f340d"
      },
      "source": [
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/yesno/ASR && \\\n",
        "  rm -rf data && \\\n",
        "  ./prepare.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-23 15:44:33 (prepare.sh:27:main) dl_dir: /content/icefall/egs/yesno/ASR/download\n",
            "2024-09-23 15:44:33 (prepare.sh:30:main) Stage 0: Download data\n",
            "/content/icefall/egs/yesno/ASR/download/waves_yesno.tar.gz: 100% 4.70M/4.70M [00:01<00:00, 3.61MB/s]\n",
            "2024-09-23 15:44:43 (prepare.sh:39:main) Stage 1: Prepare yesno manifest\n",
            "2024-09-23 15:44:46 (prepare.sh:45:main) Stage 2: Compute fbank for yesno\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/icefall/egs/yesno/ASR/./local/compute_fbank_yesno.py\", line 18, in <module>\n",
            "    from icefall.utils import get_executor\n",
            "  File \"/content/icefall/icefall/__init__.py\", line 3, in <module>\n",
            "    from . import checkpoint, decode, dist, env, utils\n",
            "  File \"/content/icefall/icefall/decode.py\", line 20, in <module>\n",
            "    import k2\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/k2/__init__.py\", line 23, in <module>\n",
            "    from _k2 import DeterminizeWeightPushingType\n",
            "ImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RAnFhhqZgPo"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1phegInRZkbl",
        "outputId": "bd58d4c6-c24b-4a12-8129-e91d833c95d4",
        "collapsed": true
      },
      "source": [
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/yesno/ASR && \\\n",
        "  ./tdnn/train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/icefall/egs/yesno/ASR/./tdnn/train.py\", line 9, in <module>\n",
            "    import k2\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/k2/__init__.py\", line 23, in <module>\n",
            "    from _k2 import DeterminizeWeightPushingType\n",
            "ImportError: libcuda.so.1: cannot open shared object file: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnwI18BKcq6e"
      },
      "source": [
        "## Decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WS-i2RdYzrx",
        "outputId": "7f694d6c-a6f2-473b-aa30-69289231cdcf"
      },
      "source": [
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/yesno/ASR && \\\n",
        "  ./tdnn/decode.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-23 15:07:40,591 INFO [decode.py:262] Decoding started\n",
            "2024-09-23 15:07:40,591 INFO [decode.py:263] {'exp_dir': PosixPath('tdnn/exp'), 'lang_dir': PosixPath('data/lang_phone'), 'feature_dim': 23, 'search_beam': 20, 'output_beam': 8, 'min_active_states': 30, 'max_active_states': 10000, 'use_double_scores': True, 'epoch': 14, 'avg': 2, 'export': False, 'feature_dir': PosixPath('data/fbank'), 'max_duration': 30.0, 'bucketing_sampler': False, 'num_buckets': 10, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': False, 'return_cuts': True, 'num_workers': 2, 'env_info': {'k2-version': '1.24.4', 'k2-build-type': 'Release', 'k2-with-cuda': True, 'k2-git-sha1': 'cf664841c6d93e21e59b40aade84869b76c919c1', 'k2-git-date': 'Thu Sep 5 19:25:17 2024', 'lhotse-version': '1.28.0.dev+git.bc2c0a2.clean', 'torch-version': '2.4.1+cu121', 'torch-cuda-available': True, 'torch-cuda-version': '12.1', 'python-version': '3.10', 'icefall-git-branch': 'master', 'icefall-git-sha1': '5c04c312-clean', 'icefall-git-date': 'Fri Sep 20 04:38:52 2024', 'icefall-path': '/content/icefall', 'k2-path': '/usr/local/lib/python3.10/dist-packages/k2/__init__.py', 'lhotse-path': '/usr/local/lib/python3.10/dist-packages/lhotse/__init__.py', 'hostname': '50c4face7696', 'IP address': '172.28.0.12'}}\n",
            "2024-09-23 15:07:40,592 INFO [lexicon.py:168] Loading pre-compiled data/lang_phone/Linv.pt\n",
            "/content/icefall/icefall/lexicon.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  L_inv = k2.Fsa.from_dict(torch.load(lang_dir / \"Linv.pt\"))\n",
            "2024-09-23 15:07:40,594 INFO [decode.py:272] device: cuda:0\n",
            "/content/icefall/egs/yesno/ASR/./tdnn/decode.py:274: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  HLG = k2.Fsa.from_dict(torch.load(f\"{params.lang_dir}/HLG.pt\", map_location=\"cpu\"))\n",
            "2024-09-23 15:07:40,840 INFO [decode.py:290] averaging ['tdnn/exp/epoch-13.pt', 'tdnn/exp/epoch-14.pt']\n",
            "/content/icefall/icefall/checkpoint.py:166: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  avg = torch.load(filenames[0], map_location=device)[\"model\"]\n",
            "/content/icefall/icefall/checkpoint.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(filenames[i], map_location=device)[\"model\"]\n",
            "2024-09-23 15:07:40,852 INFO [asr_datamodule.py:220] About to get test cuts\n",
            "2024-09-23 15:07:40,852 INFO [asr_datamodule.py:257] About to get test cuts\n",
            "2024-09-23 15:07:42,951 INFO [decode.py:203] batch 0/?, cuts processed until now is 4\n",
            "2024-09-23 15:07:44,432 INFO [decode.py:240] The transcripts are stored in tdnn/exp/recogs-test_set.txt\n",
            "2024-09-23 15:07:44,432 INFO [utils.py:657] [test_set] %WER 0.42% [1 / 240, 0 ins, 1 del, 0 sub ]\n",
            "2024-09-23 15:07:44,433 INFO [decode.py:248] Wrote detailed error stats to tdnn/exp/errs-test_set.txt\n",
            "2024-09-23 15:07:44,433 INFO [decode.py:315] Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMENow4cc53b"
      },
      "source": [
        "### Show the decoding result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yQT-VEJc3Xz",
        "outputId": "bbc30b39-4def-4419-f141-8b69a3284222",
        "collapsed": true
      },
      "source": [
        "! cd /content/icefall/egs/yesno/ASR && \\\n",
        "  cat tdnn/exp/recogs-test_set.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0_0_0_1_0_0_0_1-0:\tref=['NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES']\n",
            "0_0_0_1_0_0_0_1-0:\thyp=['NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES']\n",
            "0_0_1_0_0_0_1_0-1:\tref=['NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO']\n",
            "0_0_1_0_0_0_1_0-1:\thyp=['NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO']\n",
            "0_0_1_0_0_1_1_1-2:\tref=['NO', 'NO', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "0_0_1_0_0_1_1_1-2:\thyp=['NO', 'NO', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "0_0_1_0_1_0_0_1-3:\tref=['NO', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'YES']\n",
            "0_0_1_0_1_0_0_1-3:\thyp=['NO', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'YES']\n",
            "0_0_1_1_0_0_0_1-4:\tref=['NO', 'NO', 'YES', 'YES', 'NO', 'NO', 'NO', 'YES']\n",
            "0_0_1_1_0_0_0_1-4:\thyp=['NO', 'NO', 'YES', 'YES', 'NO', 'NO', 'NO', 'YES']\n",
            "0_0_1_1_0_1_1_0-5:\tref=['NO', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'NO']\n",
            "0_0_1_1_0_1_1_0-5:\thyp=['NO', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'NO']\n",
            "0_0_1_1_1_0_0_0-6:\tref=['NO', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n",
            "0_0_1_1_1_0_0_0-6:\thyp=['NO', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n",
            "0_0_1_1_1_1_0_0-7:\tref=['NO', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO']\n",
            "0_0_1_1_1_1_0_0-7:\thyp=['NO', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO']\n",
            "0_1_0_0_0_1_0_0-8:\tref=['NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO', 'NO']\n",
            "0_1_0_0_0_1_0_0-8:\thyp=['NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO', 'NO']\n",
            "0_1_0_0_1_0_1_0-9:\tref=['NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'NO']\n",
            "0_1_0_0_1_0_1_0-9:\thyp=['NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'NO']\n",
            "0_1_0_1_0_0_0_0-10:\tref=['NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'NO', 'NO']\n",
            "0_1_0_1_0_0_0_0-10:\thyp=['NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'NO']\n",
            "0_1_0_1_1_1_0_0-11:\tref=['NO', 'YES', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO']\n",
            "0_1_0_1_1_1_0_0-11:\thyp=['NO', 'YES', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO']\n",
            "0_1_1_0_0_1_1_1-12:\tref=['NO', 'YES', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "0_1_1_0_0_1_1_1-12:\thyp=['NO', 'YES', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "0_1_1_1_0_0_1_0-13:\tref=['NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n",
            "0_1_1_1_0_0_1_0-13:\thyp=['NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n",
            "0_1_1_1_1_0_1_0-14:\tref=['NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES', 'NO']\n",
            "0_1_1_1_1_0_1_0-14:\thyp=['NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES', 'NO']\n",
            "1_0_0_0_0_0_0_0-15:\tref=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO']\n",
            "1_0_0_0_0_0_0_0-15:\thyp=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO']\n",
            "1_0_0_0_0_0_1_1-16:\tref=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'YES', 'YES']\n",
            "1_0_0_0_0_0_1_1-16:\thyp=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'YES', 'YES']\n",
            "1_0_0_1_0_1_1_1-17:\tref=['YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES', 'YES']\n",
            "1_0_0_1_0_1_1_1-17:\thyp=['YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES', 'YES']\n",
            "1_0_1_1_0_1_1_1-18:\tref=['YES', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'YES']\n",
            "1_0_1_1_0_1_1_1-18:\thyp=['YES', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'YES']\n",
            "1_0_1_1_1_1_0_1-19:\tref=['YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES']\n",
            "1_0_1_1_1_1_0_1-19:\thyp=['YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES']\n",
            "1_1_0_0_0_1_1_1-20:\tref=['YES', 'YES', 'NO', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "1_1_0_0_0_1_1_1-20:\thyp=['YES', 'YES', 'NO', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "1_1_0_0_1_0_1_1-21:\tref=['YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES']\n",
            "1_1_0_0_1_0_1_1-21:\thyp=['YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES']\n",
            "1_1_0_1_0_1_0_0-22:\tref=['YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO']\n",
            "1_1_0_1_0_1_0_0-22:\thyp=['YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO']\n",
            "1_1_0_1_1_0_0_1-23:\tref=['YES', 'YES', 'NO', 'YES', 'YES', 'NO', 'NO', 'YES']\n",
            "1_1_0_1_1_0_0_1-23:\thyp=['YES', 'YES', 'NO', 'YES', 'YES', 'NO', 'NO', 'YES']\n",
            "1_1_0_1_1_1_1_0-24:\tref=['YES', 'YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO']\n",
            "1_1_0_1_1_1_1_0-24:\thyp=['YES', 'YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO']\n",
            "1_1_1_0_0_1_0_1-25:\tref=['YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES']\n",
            "1_1_1_0_0_1_0_1-25:\thyp=['YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES']\n",
            "1_1_1_0_1_0_1_0-26:\tref=['YES', 'YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO']\n",
            "1_1_1_0_1_0_1_0-26:\thyp=['YES', 'YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO']\n",
            "1_1_1_1_0_0_1_0-27:\tref=['YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n",
            "1_1_1_1_0_0_1_0-27:\thyp=['YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n",
            "1_1_1_1_1_0_0_0-28:\tref=['YES', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n",
            "1_1_1_1_1_0_0_0-28:\thyp=['YES', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n",
            "1_1_1_1_1_1_1_1-29:\tref=['YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES']\n",
            "1_1_1_1_1_1_1_1-29:\thyp=['YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RIxtJ-IdLob"
      },
      "source": [
        "### Show the detailed WER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lQFBS-KdIVx",
        "outputId": "f2371e04-d9a8-4667-d401-8fb8c4bdb762"
      },
      "source": [
        "! cd /content/icefall/egs/yesno/ASR && \\\n",
        "  cat tdnn/exp/errs-test_set.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%WER = 0.42\n",
            "Errors: 0 insertions, 1 deletions, 0 substitutions, over 240 reference words (239 correct)\n",
            "Search below for sections starting with PER-UTT DETAILS:, SUBSTITUTIONS:, DELETIONS:, INSERTIONS:, PER-WORD STATS:\n",
            "\n",
            "PER-UTT DETAILS: corr or (ref->hyp)  \n",
            "0_0_0_1_0_0_0_1-0:\tNO NO NO YES NO NO NO YES\n",
            "0_0_1_0_0_0_1_0-1:\tNO NO YES NO NO NO YES NO\n",
            "0_0_1_0_0_1_1_1-2:\tNO NO YES NO NO YES YES YES\n",
            "0_0_1_0_1_0_0_1-3:\tNO NO YES NO YES NO NO YES\n",
            "0_0_1_1_0_0_0_1-4:\tNO NO YES YES NO NO NO YES\n",
            "0_0_1_1_0_1_1_0-5:\tNO NO YES YES NO YES YES NO\n",
            "0_0_1_1_1_0_0_0-6:\tNO NO YES YES YES NO NO NO\n",
            "0_0_1_1_1_1_0_0-7:\tNO NO YES YES YES YES NO NO\n",
            "0_1_0_0_0_1_0_0-8:\tNO YES NO NO NO YES NO NO\n",
            "0_1_0_0_1_0_1_0-9:\tNO YES NO NO YES NO YES NO\n",
            "0_1_0_1_0_0_0_0-10:\tNO YES NO YES NO NO NO (NO->*)\n",
            "0_1_0_1_1_1_0_0-11:\tNO YES NO YES YES YES NO NO\n",
            "0_1_1_0_0_1_1_1-12:\tNO YES YES NO NO YES YES YES\n",
            "0_1_1_1_0_0_1_0-13:\tNO YES YES YES NO NO YES NO\n",
            "0_1_1_1_1_0_1_0-14:\tNO YES YES YES YES NO YES NO\n",
            "1_0_0_0_0_0_0_0-15:\tYES NO NO NO NO NO NO NO\n",
            "1_0_0_0_0_0_1_1-16:\tYES NO NO NO NO NO YES YES\n",
            "1_0_0_1_0_1_1_1-17:\tYES NO NO YES NO YES YES YES\n",
            "1_0_1_1_0_1_1_1-18:\tYES NO YES YES NO YES YES YES\n",
            "1_0_1_1_1_1_0_1-19:\tYES NO YES YES YES YES NO YES\n",
            "1_1_0_0_0_1_1_1-20:\tYES YES NO NO NO YES YES YES\n",
            "1_1_0_0_1_0_1_1-21:\tYES YES NO NO YES NO YES YES\n",
            "1_1_0_1_0_1_0_0-22:\tYES YES NO YES NO YES NO NO\n",
            "1_1_0_1_1_0_0_1-23:\tYES YES NO YES YES NO NO YES\n",
            "1_1_0_1_1_1_1_0-24:\tYES YES NO YES YES YES YES NO\n",
            "1_1_1_0_0_1_0_1-25:\tYES YES YES NO NO YES NO YES\n",
            "1_1_1_0_1_0_1_0-26:\tYES YES YES NO YES NO YES NO\n",
            "1_1_1_1_0_0_1_0-27:\tYES YES YES YES NO NO YES NO\n",
            "1_1_1_1_1_0_0_0-28:\tYES YES YES YES YES NO NO NO\n",
            "1_1_1_1_1_1_1_1-29:\tYES YES YES YES YES YES YES YES\n",
            "\n",
            "SUBSTITUTIONS: count ref -> hyp\n",
            "\n",
            "DELETIONS: count ref\n",
            "1   NO\n",
            "\n",
            "INSERTIONS: count hyp\n",
            "\n",
            "PER-WORD STATS: word  corr tot_errs count_in_ref count_in_hyp\n",
            "NO   115 1 116 115\n",
            "YES   124 0 124 124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/icefall/egs/yesno/ASR && ./tdnn/export.py --epoch 14 --avg 2\n",
        "\n",
        "#Decode a single sound file\n",
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/yesno/ASR && \\\n",
        "  ./tdnn/pretrained.py \\\n",
        "    --checkpoint ./tmp/icefall_asr_yesno_tdnn/pretrained.pt \\\n",
        "    --words-file ./tmp/icefall_asr_yesno_tdnn/lang_phone/words.txt \\\n",
        "    --HLG ./tmp/icefall_asr_yesno_tdnn/lang_phone/HLG.pt \\\n",
        "    ./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav\n",
        "\n",
        "    #./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav:\n",
        "    #NO NO YES NO YES NO NO YES"
      ],
      "metadata": {
        "id": "C8nrz1UiiQID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lIChKjOr5J0"
      },
      "source": [
        "# Pre-trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzfpY18xr-6P"
      },
      "source": [
        "### Download the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naBI_K9fr8Qn",
        "outputId": "1834915d-17ef-4540-8e51-d6b0e9f6d716"
      },
      "source": [
        "! cd /content/icefall/egs/yesno/ASR && \\\n",
        "  mkdir tmp && \\\n",
        "  cd tmp && \\\n",
        "  git lfs install && \\\n",
        "  git clone https://huggingface.co/csukuangfj/icefall_asr_yesno_tdnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'icefall_asr_yesno_tdnn'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Total 60 (delta 0), reused 0 (delta 0), pack-reused 60\u001b[K\n",
            "Unpacking objects: 100% (60/60), 2.28 MiB | 9.59 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hbcze8EsRcA",
        "outputId": "45ce18c2-cdcd-415f-97b7-30122a3375aa"
      },
      "source": [
        "! sudo apt-get install git-lfs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCkos-5msW-K",
        "outputId": "fe236298-c544-42b7-aa20-fab93862e68d"
      },
      "source": [
        "! cd /content/icefall/egs/yesno/ASR && \\\n",
        "  mkdir -p tmp && \\\n",
        "  tree tmp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: tree: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufKWViBxsc41",
        "outputId": "841b835f-e6f5-4604-e2cb-8f11ff914fe9"
      },
      "source": [
        "! sudo apt-get install tree"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 0s (286 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 120493 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJn7iUw6se1W",
        "outputId": "ba6915dc-3aa2-4ac8-caef-3a86d527de5f"
      },
      "source": [
        "! cd /content/icefall/egs/yesno/ASR && \\\n",
        "  mkdir -p tmp && \\\n",
        "  tree tmp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34mtmp\u001b[0m\n",
            "└── \u001b[01;34micefall_asr_yesno_tdnn\u001b[0m\n",
            "    ├── \u001b[01;34mlang_phone\u001b[0m\n",
            "    │   ├── \u001b[00mHLG.pt\u001b[0m\n",
            "    │   ├── \u001b[00mL_disambig.pt\u001b[0m\n",
            "    │   ├── \u001b[00mlexicon_disambig.txt\u001b[0m\n",
            "    │   ├── \u001b[00mlexicon.txt\u001b[0m\n",
            "    │   ├── \u001b[00mLinv.pt\u001b[0m\n",
            "    │   ├── \u001b[00mL.pt\u001b[0m\n",
            "    │   ├── \u001b[00mtokens.txt\u001b[0m\n",
            "    │   └── \u001b[00mwords.txt\u001b[0m\n",
            "    ├── \u001b[01;34mlm\u001b[0m\n",
            "    │   ├── \u001b[00mG.arpa\u001b[0m\n",
            "    │   └── \u001b[00mG.fst.txt\u001b[0m\n",
            "    ├── \u001b[00mpretrained.pt\u001b[0m\n",
            "    ├── \u001b[00mREADME.md\u001b[0m\n",
            "    └── \u001b[01;34mtest_waves\u001b[0m\n",
            "        ├── \u001b[01;35m0_0_0_1_0_0_0_1.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_0_1_0_0_0_1_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_0_1_0_0_1_1_1.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_0_1_0_1_0_0_1.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_0_1_1_0_0_0_1.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_0_1_1_0_1_1_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_0_1_1_1_0_0_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_0_1_1_1_1_0_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_1_0_0_0_1_0_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_1_0_0_1_0_1_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_1_0_1_0_0_0_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_1_0_1_1_1_0_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_1_1_0_0_1_1_1.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_1_1_1_0_0_1_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m0_1_1_1_1_0_1_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_0_0_0_0_0_0_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_0_0_0_0_0_1_1.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_0_0_1_0_1_1_1.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_0_1_1_0_1_1_1.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_0_1_1_1_1_0_1.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_1_0_0_0_1_1_1.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_1_0_0_1_0_1_1.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_1_0_1_0_1_0_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_1_0_1_1_0_0_1.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_1_0_1_1_1_1_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_1_1_0_0_1_0_1.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_1_1_0_1_0_1_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_1_1_1_0_0_1_0.wav\u001b[0m\n",
            "        ├── \u001b[01;35m1_1_1_1_1_0_0_0.wav\u001b[0m\n",
            "        └── \u001b[01;35m1_1_1_1_1_1_1_1.wav\u001b[0m\n",
            "\n",
            "4 directories, 42 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8We8jsdsiPw",
        "outputId": "d749994b-5fa4-498f-d86a-cab1fdd5e6fd"
      },
      "source": [
        "! cd /content/icefall/egs/yesno/ASR && \\\n",
        "  soxi tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: soxi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69CgbooXsorj",
        "outputId": "e16c2b16-7222-437c-d912-ef4bfbbfe9e6"
      },
      "source": [
        "! sudo apt-get install sox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base\n",
            "  libsox3 libwavpack1\n",
            "Suggested packages:\n",
            "  libsox-fmt-all\n",
            "The following NEW packages will be installed:\n",
            "  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base\n",
            "  libsox3 libwavpack1 sox\n",
            "0 upgraded, 7 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 617 kB of archives.\n",
            "After this operation, 1,760 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2build0.22.04.1 [240 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2build0.22.04.1 [11.2 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2build0.22.04.1 [33.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 sox amd64 14.4.2+git20190427-2+deb11u2build0.22.04.1 [104 kB]\n",
            "Fetched 617 kB in 0s (1,718 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 7.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 120501 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../1-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../2-libsox3_14.4.2+git20190427-2+deb11u2build0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2build0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../3-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2build0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2build0.22.04.1) ...\n",
            "Selecting previously unselected package libwavpack1:amd64.\n",
            "Preparing to unpack .../4-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
            "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../5-libsox-fmt-base_14.4.2+git20190427-2+deb11u2build0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2build0.22.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../6-sox_14.4.2+git20190427-2+deb11u2build0.22.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2+git20190427-2+deb11u2build0.22.04.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2build0.22.04.1) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2build0.22.04.1) ...\n",
            "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2build0.22.04.1) ...\n",
            "Setting up sox (14.4.2+git20190427-2+deb11u2build0.22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRQ85XoTsqVq",
        "outputId": "1f56bb85-3334-4a11-ba8c-21a9be640715"
      },
      "source": [
        "! cd /content/icefall/egs/yesno/ASR && \\\n",
        "  soxi tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input File     : 'tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav'\n",
            "Channels       : 1\n",
            "Sample Rate    : 8000\n",
            "Precision      : 16-bit\n",
            "Duration       : 00:00:06.76 = 54080 samples ~ 507 CDDA sectors\n",
            "File Size      : 108k\n",
            "Bit Rate       : 128k\n",
            "Sample Encoding: 16-bit Signed Integer PCM\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtEYXq6Lt4gH"
      },
      "source": [
        "## Download kaldifeat\n",
        "\n",
        "See https://csukuangfj.github.io/kaldifeat/installation/from_wheels.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yXGrYBbt7Xd",
        "outputId": "e3360454-836f-4056-926a-bd9c33e44c72"
      },
      "source": [
        "! pip install kaldifeat==1.25.0.dev20230726+cuda11.8.torch2.0.1  -f https://csukuangfj.github.io/kaldifeat/cuda.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://csukuangfj.github.io/kaldifeat/cuda.html\n",
            "Collecting kaldifeat==1.25.0.dev20230726+cuda11.8.torch2.0.1\n",
            "  Downloading https://huggingface.co/csukuangfj/kaldifeat/resolve/main/ubuntu-cuda/kaldifeat-1.25.0.dev20230726%2Bcuda11.8.torch2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (574 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m574.0/574.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaldifeat\n",
            "Successfully installed kaldifeat-1.25.0.dev20230726+cuda11.8.torch2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWmnk4YwsyQn"
      },
      "source": [
        "## Inference with a pre-trained model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-YdwbyfwS7F"
      },
      "source": [
        "### View help information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmU6_ZbLsvAg",
        "outputId": "ae790003-471f-485a-8185-90971dcaacf2"
      },
      "source": [
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/yesno/ASR && \\\n",
        "  ./tdnn/pretrained.py --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: pretrained.py\n",
            "       [-h]\n",
            "       --checkpoint\n",
            "       CHECKPOINT\n",
            "       --words-file\n",
            "       WORDS_FILE\n",
            "       --HLG\n",
            "       HLG\n",
            "       sound_files\n",
            "       [sound_files ...]\n",
            "\n",
            "positional arguments:\n",
            "  sound_files\n",
            "    The input\n",
            "    sound\n",
            "    file(s) to\n",
            "    transcribe.\n",
            "    Supported\n",
            "    formats are\n",
            "    those\n",
            "    supported\n",
            "    by torchaud\n",
            "    io.load().\n",
            "    For\n",
            "    example,\n",
            "    wav and\n",
            "    flac are\n",
            "    supported.\n",
            "    The sample\n",
            "    rate has to\n",
            "    be 16kHz.\n",
            "\n",
            "options:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  --checkpoint CHECKPOINT\n",
            "    Path to the\n",
            "    checkpoint.\n",
            "    The\n",
            "    checkpoint\n",
            "    is assumed\n",
            "    to be saved\n",
            "    by icefall.\n",
            "    checkpoint.\n",
            "    save_checkp\n",
            "    oint().\n",
            "    (default:\n",
            "    None)\n",
            "  --words-file WORDS_FILE\n",
            "    Path to\n",
            "    words.txt\n",
            "    (default:\n",
            "    None)\n",
            "  --HLG HLG\n",
            "    Path to\n",
            "    HLG.pt.\n",
            "    (default:\n",
            "    None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2zEQaGxwUob"
      },
      "source": [
        "### Decode a single sound file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxMbwNH0s9Sl",
        "outputId": "e1d6f9cb-2a46-40d6-c3f6-7e303990655e"
      },
      "source": [
        "#Decode a single sound file\n",
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/yesno/ASR && \\\n",
        "  ./tdnn/pretrained.py \\\n",
        "    --checkpoint ./tmp/icefall_asr_yesno_tdnn/pretrained.pt \\\n",
        "    --words-file ./tmp/icefall_asr_yesno_tdnn/lang_phone/words.txt \\\n",
        "    --HLG ./tmp/icefall_asr_yesno_tdnn/lang_phone/HLG.pt \\\n",
        "    ./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav\n",
        "\n",
        "    #./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav:\n",
        "    #NO NO YES NO YES NO NO YES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-27 05:12:18,157 INFO [pretrained.py:116] {'feature_dim': 23, 'num_classes': 4, 'sample_rate': 8000, 'search_beam': 20, 'output_beam': 8, 'min_active_states': 30, 'max_active_states': 10000, 'use_double_scores': True, 'checkpoint': './tmp/icefall_asr_yesno_tdnn/pretrained.pt', 'words_file': './tmp/icefall_asr_yesno_tdnn/lang_phone/words.txt', 'HLG': './tmp/icefall_asr_yesno_tdnn/lang_phone/HLG.pt', 'sound_files': ['./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav']}\n",
            "2023-07-27 05:12:18,177 INFO [pretrained.py:122] device: cuda:0\n",
            "2023-07-27 05:12:18,177 INFO [pretrained.py:124] Creating model\n",
            "2023-07-27 05:12:20,058 INFO [pretrained.py:136] Loading HLG from ./tmp/icefall_asr_yesno_tdnn/lang_phone/HLG.pt\n",
            "2023-07-27 05:12:20,061 INFO [pretrained.py:140] Constructing Fbank computer\n",
            "2023-07-27 05:12:20,061 INFO [pretrained.py:150] Reading sound files: ['./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav']\n",
            "2023-07-27 05:12:20,062 INFO [pretrained.py:156] Decoding started\n",
            "2023-07-27 05:12:24,120 INFO [pretrained.py:193] \n",
            "./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav:\n",
            "NO NO YES NO YES NO NO YES\n",
            "\n",
            "\n",
            "2023-07-27 05:12:24,120 INFO [pretrained.py:195] Decoding Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxT9rP6WwXdO"
      },
      "source": [
        "### Decode multiple sound files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6bYzDehvWZI",
        "outputId": "db9401ec-a73a-4826-bfa6-2080a57909f7"
      },
      "source": [
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/yesno/ASR && \\\n",
        "  ./tdnn/pretrained.py \\\n",
        "    --checkpoint ./tmp/icefall_asr_yesno_tdnn/pretrained.pt \\\n",
        "    --words-file ./tmp/icefall_asr_yesno_tdnn/lang_phone/words.txt \\\n",
        "    --HLG ./tmp/icefall_asr_yesno_tdnn/lang_phone/HLG.pt \\\n",
        "    ./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav \\\n",
        "    ./tmp/icefall_asr_yesno_tdnn/test_waves/1_0_1_1_0_1_1_1.wav"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-27 05:12:28,541 INFO [pretrained.py:116] {'feature_dim': 23, 'num_classes': 4, 'sample_rate': 8000, 'search_beam': 20, 'output_beam': 8, 'min_active_states': 30, 'max_active_states': 10000, 'use_double_scores': True, 'checkpoint': './tmp/icefall_asr_yesno_tdnn/pretrained.pt', 'words_file': './tmp/icefall_asr_yesno_tdnn/lang_phone/words.txt', 'HLG': './tmp/icefall_asr_yesno_tdnn/lang_phone/HLG.pt', 'sound_files': ['./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav', './tmp/icefall_asr_yesno_tdnn/test_waves/1_0_1_1_0_1_1_1.wav']}\n",
            "2023-07-27 05:12:28,562 INFO [pretrained.py:122] device: cuda:0\n",
            "2023-07-27 05:12:28,562 INFO [pretrained.py:124] Creating model\n",
            "2023-07-27 05:12:30,331 INFO [pretrained.py:136] Loading HLG from ./tmp/icefall_asr_yesno_tdnn/lang_phone/HLG.pt\n",
            "2023-07-27 05:12:30,334 INFO [pretrained.py:140] Constructing Fbank computer\n",
            "2023-07-27 05:12:30,334 INFO [pretrained.py:150] Reading sound files: ['./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav', './tmp/icefall_asr_yesno_tdnn/test_waves/1_0_1_1_0_1_1_1.wav']\n",
            "2023-07-27 05:12:30,336 INFO [pretrained.py:156] Decoding started\n",
            "2023-07-27 05:12:31,935 INFO [pretrained.py:193] \n",
            "./tmp/icefall_asr_yesno_tdnn/test_waves/0_0_1_0_1_0_0_1.wav:\n",
            "NO NO YES NO YES NO NO YES\n",
            "\n",
            "./tmp/icefall_asr_yesno_tdnn/test_waves/1_0_1_1_0_1_1_1.wav:\n",
            "YES NO YES YES NO YES YES YES\n",
            "\n",
            "\n",
            "2023-07-27 05:12:31,935 INFO [pretrained.py:195] Decoding Done\n"
          ]
        }
      ]
    }
  ]
}