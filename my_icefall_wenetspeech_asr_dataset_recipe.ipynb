{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diyism/colab_kaldi2/blob/main/my_icefall_wenetspeech_asr_dataset_recipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "!umount /content/drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0z2qwQeesfa",
        "outputId": "36ca00ff-8972-4b07-983b-dcde3ce3d6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "total 4\n",
            "drwx------ 2 root root 4096 Sep 26 04:03 kws_create_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls -al icefall/egs/wenetspeech/ASR\n",
        "#!ls -al /content/drive/MyDrive/ColabData/KWS/kws_create_dataset/train\n",
        "#!lhotse kaldi import --help\n",
        "#!cd /content/drive/MyDrive/ColabData/KWS/kws_create_dataset && lhotse kaldi import ./train/ 16000 ./train_manifests/\n",
        "!ls -al /content/drive/MyDrive/ColabData/KWS/kws_create_dataset/train_manifests\n",
        "\n",
        "#-f ./train_manifests/features.jsonl.gz \\\n",
        "!cd /content/drive/MyDrive/ColabData/KWS/kws_create_dataset && lhotse cut simple \\\n",
        "  -r ./train_manifests/recordings.jsonl.gz \\\n",
        "  -s ./train_manifests/supervisions.jsonl.gz \\\n",
        "  ./myvoice_train.jsonl.gz\n",
        "\n",
        "!ls -al /content/drive/MyDrive/ColabData/KWS/kws_create_dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJcYehXRDOwK",
        "outputId": "81d8159b-9d7f-4b98-c51f-d44d46d07d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2\n",
            "-rw------- 1 root root 358 Sep 28 15:56 cuts.jsonl.gz\n",
            "-rw------- 1 root root 209 Sep 28 15:56 recordings.jsonl.gz\n",
            "-rw------- 1 root root 205 Sep 28 15:56 supervisions.jsonl.gz\n",
            "total 414\n",
            "-rw------- 1 root root     58 Sep 26 02:38 4_me.txt\n",
            "-rw------- 1 root root 224044 Sep 26 02:34 4_me.wav\n",
            "-rw------- 1 root root     58 Sep 26 03:46 4.txt\n",
            "-rw------- 1 root root 147216 Sep 26 02:39 4.wav\n",
            "-rw------- 1 root root     15 Sep 26 02:40 jiang3you3bo2.txt\n",
            "-rw------- 1 root root  41644 Sep 26 02:40 jiang3you3bo2.wav\n",
            "-rw------- 1 root root    367 Sep 28 16:22 myvoice_train.jsonl.gz\n",
            "drwx------ 2 root root   4096 Sep 28 15:47 train\n",
            "drwx------ 2 root root   4096 Sep 28 15:56 train_manifests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AliAaueDNteG",
        "outputId": "7a388a50-054d-4bcd-b6b7-32085d8b268c",
        "collapsed": true
      },
      "source": [
        "# originate from https://k2-fsa.github.io/icefall/recipes/Non-streaming-ASR/yesno/tdnn.html#colab-notebook\n",
        "#1. Install PyTorch, torchaudio, k2\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torchaudio\n",
        "import torchaudio\n",
        "print(torchaudio.__version__)\n",
        "\n",
        "#the cuda version and torch version should match the upper printed verions\n",
        "!pip install -q k2==1.24.4.dev20240905+cuda12.1.torch2.4.1 -f https://k2-fsa.github.io/k2/cuda.html\n",
        "!python3 -m k2.version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.1+cu121\n",
            "2.4.1+cu121\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting environment information...\n",
            "\n",
            "k2 version: 1.24.4\n",
            "Build type: Release\n",
            "Git SHA1: cf664841c6d93e21e59b40aade84869b76c919c1\n",
            "Git date: Thu Sep 5 19:25:17 2024\n",
            "Cuda used to build k2: 12.1\n",
            "cuDNN used to build k2: \n",
            "Python version used to build k2: 3.10\n",
            "OS used to build k2: CentOS Linux release 7.9.2009 (Core)\n",
            "CMake version: 3.30.2\n",
            "GCC version: 9.3.1\n",
            "CMAKE_CUDA_FLAGS: -Wno-deprecated-gpu-targets -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_50,code=sm_50 -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_60,code=sm_60 -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_61,code=sm_61 -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_70,code=sm_70 -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_75,code=sm_75 -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w --expt-extended-lambda -gencode arch=compute_86,code=sm_86 -DONNX_NAMESPACE=onnx_c2 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_89,code=sm_89 -gencode arch=compute_90,code=sm_90 -Xcudafe --diag_suppress=cc_clobber_ignored,--diag_suppress=field_without_dll_interface,--diag_suppress=base_class_has_different_dll_interface,--diag_suppress=dll_interface_conflict_none_assumed,--diag_suppress=dll_interface_conflict_dllexport_assumed,--diag_suppress=bad_friend_decl --expt-relaxed-constexpr --expt-extended-lambda -D_GLIBCXX_USE_CXX11_ABI=0 --compiler-options -Wall  --compiler-options -Wno-strict-overflow  --compiler-options -Wno-unknown-pragmas \n",
            "CMAKE_CXX_FLAGS:  -D_GLIBCXX_USE_CXX11_ABI=0 -Wno-unused-variable  -Wno-strict-overflow \n",
            "PyTorch version used to build k2: 2.4.1+cu121\n",
            "PyTorch is using Cuda: 12.1\n",
            "NVTX enabled: True\n",
            "With CUDA: True\n",
            "Disable debug: True\n",
            "Sync kernels : False\n",
            "Disable checks: False\n",
            "Max cpu memory allocate: 214748364800 bytes (or 200.0 GB)\n",
            "k2 abort: False\n",
            "__file__: /usr/local/lib/python3.10/dist-packages/k2/version/version.py\n",
            "_k2.__file__: /usr/local/lib/python3.10/dist-packages/_k2.cpython-310-x86_64-linux-gnu.so\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SsFZwCESWz_",
        "outputId": "ae95db07-40a1-4b11-a9cf-170e7372cefe",
        "collapsed": true
      },
      "source": [
        "#2. install lhotse\n",
        "#Normally, we would use pip install lhotse. However, the yesno recipe is added recently and has not been released to PyPI yet,\n",
        "#so we install the latest unreleased version here.\n",
        "!pip install -q git+https://github.com/lhotse-speech/lhotse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for lhotse (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP4RZ31xTKzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "1220c03d-1fb3-46fd-a083-e42d3b37137f"
      },
      "source": [
        "#3. install icefall\n",
        "#k2-icefall is a collection of Python scripts.You don't need to install it. What you need to do is to get its source code,\n",
        "#install its dependencies, and set the PYTHONPATH pointing to it.\n",
        "!git clone https://github.com/k2-fsa/icefall\n",
        "!pip install -q --upgrade onnxconverter-common\n",
        "!cd icefall && pip install -q -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'icefall'...\n",
            "remote: Enumerating objects: 18395, done.\u001b[K\n",
            "remote: Counting objects: 100% (703/703), done.\u001b[K\n",
            "remote: Compressing objects: 100% (384/384), done.\u001b[K\n",
            "remote: Total 18395 (delta 373), reused 548 (delta 278), pack-reused 17692 (from 1)\u001b[K\n",
            "Receiving objects: 100% (18395/18395), 20.29 MiB | 18.44 MiB/s, done.\n",
            "Resolving deltas: 100% (12469/12469), done.\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m595.8/595.8 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m678.1/678.1 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.1/66.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzyw8VyfUjUB",
        "outputId": "48339aa2-3de0-494f-edd0-c48388869d14"
      },
      "source": [
        "#4. data preparation\n",
        "\n",
        "# To remove the following warning message\n",
        "# 2023-07-27 05:03:07.156920: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
        "#! pip uninstall -y tensorflow\n",
        "\n",
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/wenetspeech/ASR && \\\n",
        "  rm -rf data && \\\n",
        "  ./prepare.sh\n",
        "\n",
        "#!git clone https://github.com/wenet-e2e/WenetSpeech.git\n",
        "#!cd WenetSpeech && echo 'M2h1....' > SAFEBOX/password\n",
        "#!cd WenetSpeech && bash utils/download_wenetspeech.sh DOWNLOAD_DIR UNTAR_DIR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-25 14:29:08 (prepare.sh:25:main) Stage 0: Prepare wewetspeech dataset.\n",
            "/content/icefall/egs/wenetspeech/ASR /content/icefall/egs/wenetspeech/KWS\n",
            "2024-09-25 14:29:08 (prepare.sh:48:main) dl_dir: /content/icefall/egs/wenetspeech/ASR/download\n",
            "2024-09-25 14:29:08 (prepare.sh:51:main) Stage 0: Download data\n",
            "2024-09-25 14:29:08 (prepare.sh:61:main) Stage 0: You should download WenetSpeech first\n",
            "Cloning into 'WenetSpeech'...\n",
            "remote: Enumerating objects: 397, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 397 (delta 51), reused 44 (delta 42), pack-reused 319 (from 1)\u001b[K\n",
            "Receiving objects: 100% (397/397), 3.80 MiB | 7.49 MiB/s, done.\n",
            "Resolving deltas: 100% (125/125), done.\n",
            "utils/download_wenetspeech.sh: Start to download WenetSpeech user agreement\n",
            "--2024-09-25 14:29:10--  http://wenet.meeting.tencent.com/WenetSpeech/TERMS_OF_ACCESS\n",
            "Resolving wenet.meeting.tencent.com (wenet.meeting.tencent.com)... 116.196.149.98, 36.249.92.207, 113.201.158.139, ...\n",
            "Connecting to wenet.meeting.tencent.com (wenet.meeting.tencent.com)|116.196.149.98|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1388 (1.4K) [application/octet-stream]\n",
            "Saving to: ‘/content/WenetSpeech/DOWNLOAD_DIR/TERMS_OF_ACCESS’\n",
            "\n",
            "TERMS_OF_ACCESS     100%[===================>]   1.36K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-09-25 14:29:11 (161 KB/s) - ‘/content/WenetSpeech/DOWNLOAD_DIR/TERMS_OF_ACCESS’ saved [1388/1388]\n",
            "\n",
            "\u001b[0;32m\n",
            "BY PROCEEDING YOU AGREE TO THE FOLLOWING WENETSPEECH TERMS OF ACCESS:\n",
            "\n",
            "=============== WENETSPEECH DATASET TERMS OF ACCESS ===============\n",
            "[RESEARCHER_FULLNAME] (the \"Researcher\") has requested permission to use the WenetSpeech database. In exchange for such permission, Researcher hereby agrees to the following terms and conditions:\n",
            "\n",
            "1. Researcher shall use the Database only for non-commercial research and educational purposes.\n",
            "2. The authors make no representations or warranties regarding the Database, including but not limited to warranties of non-infringement or fitness for a particular purpose.\n",
            "3. Researcher accepts full responsibility for his or her use of the Database and shall defend and indemnify the authors of WenetSpeech, including their employees, Trustees, officers and agents, against any and all claims arising from Researcher's use of the Database, including but not limited to Researcher's use of any copies of copyrighted audio files that he or she may create from the Database.\n",
            "4. Researcher may provide research associates and colleagues with access to the Database provided that they first agree to be bound by these terms and conditions.\n",
            "5. The authors reserve the right to terminate Researcher's access to the Database at any time.\n",
            "6. If Researcher is employed by a for-profit, commercial entity, Researcher's employer shall also be bound by these terms and conditions, and Researcher hereby represents that he or she is fully authorized to enter into this agreement on behalf of such employer.\n",
            "==================================================================\n",
            "utils/download_wenetspeech.sh: WenetSpeech downloading will start in 5 seconds\n",
            "\n",
            "5\n",
            "4\n",
            "3\n",
            "2\n",
            "1\n",
            "\u001b[0m\n",
            "utils/download_wenetspeech.sh: Start to download WenetSpeech files(*.aes.tgz)\n",
            "utils/download_wenetspeech.sh: Downloading WenetSpeech.json.aes.tgz remote_md5=9fa37bb17b32904b88b61111e4728aa9\n",
            "--2024-09-25 14:29:16--  http://wenet.meeting.tencent.com/WenetSpeech/WenetSpeech.json.aes.tgz\n",
            "Resolving wenet.meeting.tencent.com (wenet.meeting.tencent.com)... 116.196.149.98, 36.249.92.207, 113.201.158.139, ...\n",
            "Connecting to wenet.meeting.tencent.com (wenet.meeting.tencent.com)|116.196.149.98|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 651275680 (621M) [application/gzip]\n",
            "Saving to: ‘/content/WenetSpeech/DOWNLOAD_DIR/WenetSpeech.json.aes.tgz’\n",
            "\n",
            "WenetSpeech.json.ae  12%[=>                  ]  80.42M  6.28MB/s    eta 1m 49s ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1phegInRZkbl",
        "outputId": "3254fa40-a4ba-44a3-8361-abf0beba72e8",
        "collapsed": true
      },
      "source": [
        "#5.training\n",
        "\n",
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/WenetSpeech/ASR && \\\n",
        "  ./zipformer/train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: /content/icefall/egs/yesno/ASR: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6. decode a single sound file\n",
        "!pip install kaldifeat==1.25.5.dev20240914+cuda12.1.torch2.4.1  -f https://csukuangfj.github.io/kaldifeat/cuda.html\n",
        "\n",
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/yesno/ASR && \\\n",
        "  ./tdnn/pretrained.py \\\n",
        "    --checkpoint /content/icefall/egs/yesno/ASR/tdnn/exp/epoch-14.pt \\\n",
        "    --words-file /content/icefall/egs/yesno/ASR/data/lang_phone/words.txt \\\n",
        "    --HLG /content/icefall/egs/yesno/ASR/data/lang_phone/HLG.pt \\\n",
        "    /content/icefall/egs/yesno/ASR/download/waves_yesno/0_0_1_0_1_0_0_1.wav"
      ],
      "metadata": {
        "id": "C8nrz1UiiQID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd8f7bf-a1cf-41c7-afd8-0756ebc89da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://csukuangfj.github.io/kaldifeat/cuda.html\n",
            "Requirement already satisfied: kaldifeat==1.25.5.dev20240914+cuda12.1.torch2.4.1 in /usr/local/lib/python3.10/dist-packages (1.25.5.dev20240914+cuda12.1.torch2.4.1)\n",
            "2024-09-23 16:50:45,387 INFO [pretrained.py:136] {'feature_dim': 23, 'num_classes': 4, 'sample_rate': 8000, 'search_beam': 20, 'output_beam': 8, 'min_active_states': 30, 'max_active_states': 10000, 'use_double_scores': True, 'checkpoint': '/content/icefall/egs/yesno/ASR/tdnn/exp/epoch-14.pt', 'words_file': '/content/icefall/egs/yesno/ASR/data/lang_phone/words.txt', 'HLG': '/content/icefall/egs/yesno/ASR/data/lang_phone/HLG.pt', 'sound_files': ['/content/icefall/egs/yesno/ASR/download/waves_yesno/0_0_1_0_1_0_0_1.wav']}\n",
            "2024-09-23 16:50:45,407 INFO [pretrained.py:142] device: cuda:0\n",
            "2024-09-23 16:50:45,407 INFO [pretrained.py:144] Creating model\n",
            "/content/icefall/egs/yesno/ASR/./tdnn/pretrained.py:151: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(args.checkpoint, map_location=\"cpu\")\n",
            "2024-09-23 16:50:45,530 INFO [pretrained.py:156] Loading HLG from /content/icefall/egs/yesno/ASR/data/lang_phone/HLG.pt\n",
            "/content/icefall/egs/yesno/ASR/./tdnn/pretrained.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  HLG = k2.Fsa.from_dict(torch.load(params.HLG, map_location=\"cpu\"))\n",
            "2024-09-23 16:50:45,533 INFO [pretrained.py:160] Constructing Fbank computer\n",
            "2024-09-23 16:50:45,533 INFO [pretrained.py:171] Reading sound files: ['/content/icefall/egs/yesno/ASR/download/waves_yesno/0_0_1_0_1_0_0_1.wav']\n",
            "2024-09-23 16:50:45,543 INFO [pretrained.py:177] Decoding started\n",
            "2024-09-23 16:50:46,622 INFO [pretrained.py:213] \n",
            "/content/icefall/egs/yesno/ASR/download/waves_yesno/0_0_1_0_1_0_0_1.wav:\n",
            "NO NO YES NO YES NO NO YES\n",
            "\n",
            "\n",
            "2024-09-23 16:50:46,622 INFO [pretrained.py:215] Decoding Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WS-i2RdYzrx",
        "outputId": "15e87dca-ab42-4457-ff1d-8a743e733a8e"
      },
      "source": [
        "#7. decode all waves\n",
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/yesno/ASR && \\\n",
        "  ./tdnn/decode.py\n",
        "\n",
        "! cd /content/icefall/egs/yesno/ASR && \\\n",
        "  cat tdnn/exp/recogs-test_set.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-23 16:51:54,314 INFO [decode.py:262] Decoding started\n",
            "2024-09-23 16:51:54,314 INFO [decode.py:263] {'exp_dir': PosixPath('tdnn/exp'), 'lang_dir': PosixPath('data/lang_phone'), 'feature_dim': 23, 'search_beam': 20, 'output_beam': 8, 'min_active_states': 30, 'max_active_states': 10000, 'use_double_scores': True, 'epoch': 14, 'avg': 2, 'export': False, 'feature_dir': PosixPath('data/fbank'), 'max_duration': 30.0, 'bucketing_sampler': False, 'num_buckets': 10, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': False, 'return_cuts': True, 'num_workers': 2, 'env_info': {'k2-version': '1.24.4', 'k2-build-type': 'Release', 'k2-with-cuda': True, 'k2-git-sha1': 'cf664841c6d93e21e59b40aade84869b76c919c1', 'k2-git-date': 'Thu Sep 5 19:25:17 2024', 'lhotse-version': '1.28.0.dev+git.bc2c0a2.clean', 'torch-version': '2.4.1+cu121', 'torch-cuda-available': True, 'torch-cuda-version': '12.1', 'python-version': '3.10', 'icefall-git-branch': 'master', 'icefall-git-sha1': '5c04c312-clean', 'icefall-git-date': 'Fri Sep 20 04:38:52 2024', 'icefall-path': '/content/icefall', 'k2-path': '/usr/local/lib/python3.10/dist-packages/k2/__init__.py', 'lhotse-path': '/usr/local/lib/python3.10/dist-packages/lhotse/__init__.py', 'hostname': 'bdf1923fd1fe', 'IP address': '172.28.0.12'}}\n",
            "2024-09-23 16:51:54,315 INFO [lexicon.py:168] Loading pre-compiled data/lang_phone/Linv.pt\n",
            "/content/icefall/icefall/lexicon.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  L_inv = k2.Fsa.from_dict(torch.load(lang_dir / \"Linv.pt\"))\n",
            "2024-09-23 16:51:54,316 INFO [decode.py:272] device: cuda:0\n",
            "/content/icefall/egs/yesno/ASR/./tdnn/decode.py:274: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  HLG = k2.Fsa.from_dict(torch.load(f\"{params.lang_dir}/HLG.pt\", map_location=\"cpu\"))\n",
            "2024-09-23 16:51:54,437 INFO [decode.py:290] averaging ['tdnn/exp/epoch-13.pt', 'tdnn/exp/epoch-14.pt']\n",
            "/content/icefall/icefall/checkpoint.py:166: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  avg = torch.load(filenames[0], map_location=device)[\"model\"]\n",
            "/content/icefall/icefall/checkpoint.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(filenames[i], map_location=device)[\"model\"]\n",
            "2024-09-23 16:51:54,441 INFO [asr_datamodule.py:220] About to get test cuts\n",
            "2024-09-23 16:51:54,441 INFO [asr_datamodule.py:257] About to get test cuts\n",
            "2024-09-23 16:51:56,189 INFO [decode.py:203] batch 0/?, cuts processed until now is 4\n",
            "2024-09-23 16:51:57,729 INFO [decode.py:240] The transcripts are stored in tdnn/exp/recogs-test_set.txt\n",
            "2024-09-23 16:51:57,729 INFO [utils.py:657] [test_set] %WER 0.42% [1 / 240, 0 ins, 1 del, 0 sub ]\n",
            "2024-09-23 16:51:57,731 INFO [decode.py:248] Wrote detailed error stats to tdnn/exp/errs-test_set.txt\n",
            "2024-09-23 16:51:57,731 INFO [decode.py:315] Done!\n",
            "0_0_0_1_0_0_0_1-0:\tref=['NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES']\n",
            "0_0_0_1_0_0_0_1-0:\thyp=['NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES']\n",
            "0_0_1_0_0_0_1_0-1:\tref=['NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO']\n",
            "0_0_1_0_0_0_1_0-1:\thyp=['NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO']\n",
            "0_0_1_0_0_1_1_1-2:\tref=['NO', 'NO', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "0_0_1_0_0_1_1_1-2:\thyp=['NO', 'NO', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "0_0_1_0_1_0_0_1-3:\tref=['NO', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'YES']\n",
            "0_0_1_0_1_0_0_1-3:\thyp=['NO', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'YES']\n",
            "0_0_1_1_0_0_0_1-4:\tref=['NO', 'NO', 'YES', 'YES', 'NO', 'NO', 'NO', 'YES']\n",
            "0_0_1_1_0_0_0_1-4:\thyp=['NO', 'NO', 'YES', 'YES', 'NO', 'NO', 'NO', 'YES']\n",
            "0_0_1_1_0_1_1_0-5:\tref=['NO', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'NO']\n",
            "0_0_1_1_0_1_1_0-5:\thyp=['NO', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'NO']\n",
            "0_0_1_1_1_0_0_0-6:\tref=['NO', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n",
            "0_0_1_1_1_0_0_0-6:\thyp=['NO', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n",
            "0_0_1_1_1_1_0_0-7:\tref=['NO', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO']\n",
            "0_0_1_1_1_1_0_0-7:\thyp=['NO', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO']\n",
            "0_1_0_0_0_1_0_0-8:\tref=['NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO', 'NO']\n",
            "0_1_0_0_0_1_0_0-8:\thyp=['NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO', 'NO']\n",
            "0_1_0_0_1_0_1_0-9:\tref=['NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'NO']\n",
            "0_1_0_0_1_0_1_0-9:\thyp=['NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'NO']\n",
            "0_1_0_1_0_0_0_0-10:\tref=['NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'NO', 'NO']\n",
            "0_1_0_1_0_0_0_0-10:\thyp=['NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'NO']\n",
            "0_1_0_1_1_1_0_0-11:\tref=['NO', 'YES', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO']\n",
            "0_1_0_1_1_1_0_0-11:\thyp=['NO', 'YES', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO']\n",
            "0_1_1_0_0_1_1_1-12:\tref=['NO', 'YES', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "0_1_1_0_0_1_1_1-12:\thyp=['NO', 'YES', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "0_1_1_1_0_0_1_0-13:\tref=['NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n",
            "0_1_1_1_0_0_1_0-13:\thyp=['NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n",
            "0_1_1_1_1_0_1_0-14:\tref=['NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES', 'NO']\n",
            "0_1_1_1_1_0_1_0-14:\thyp=['NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES', 'NO']\n",
            "1_0_0_0_0_0_0_0-15:\tref=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO']\n",
            "1_0_0_0_0_0_0_0-15:\thyp=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO']\n",
            "1_0_0_0_0_0_1_1-16:\tref=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'YES', 'YES']\n",
            "1_0_0_0_0_0_1_1-16:\thyp=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'YES', 'YES']\n",
            "1_0_0_1_0_1_1_1-17:\tref=['YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES', 'YES']\n",
            "1_0_0_1_0_1_1_1-17:\thyp=['YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES', 'YES']\n",
            "1_0_1_1_0_1_1_1-18:\tref=['YES', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'YES']\n",
            "1_0_1_1_0_1_1_1-18:\thyp=['YES', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'YES']\n",
            "1_0_1_1_1_1_0_1-19:\tref=['YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES']\n",
            "1_0_1_1_1_1_0_1-19:\thyp=['YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES']\n",
            "1_1_0_0_0_1_1_1-20:\tref=['YES', 'YES', 'NO', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "1_1_0_0_0_1_1_1-20:\thyp=['YES', 'YES', 'NO', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "1_1_0_0_1_0_1_1-21:\tref=['YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES']\n",
            "1_1_0_0_1_0_1_1-21:\thyp=['YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES']\n",
            "1_1_0_1_0_1_0_0-22:\tref=['YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO']\n",
            "1_1_0_1_0_1_0_0-22:\thyp=['YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO']\n",
            "1_1_0_1_1_0_0_1-23:\tref=['YES', 'YES', 'NO', 'YES', 'YES', 'NO', 'NO', 'YES']\n",
            "1_1_0_1_1_0_0_1-23:\thyp=['YES', 'YES', 'NO', 'YES', 'YES', 'NO', 'NO', 'YES']\n",
            "1_1_0_1_1_1_1_0-24:\tref=['YES', 'YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO']\n",
            "1_1_0_1_1_1_1_0-24:\thyp=['YES', 'YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO']\n",
            "1_1_1_0_0_1_0_1-25:\tref=['YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES']\n",
            "1_1_1_0_0_1_0_1-25:\thyp=['YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES']\n",
            "1_1_1_0_1_0_1_0-26:\tref=['YES', 'YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO']\n",
            "1_1_1_0_1_0_1_0-26:\thyp=['YES', 'YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO']\n",
            "1_1_1_1_0_0_1_0-27:\tref=['YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n",
            "1_1_1_1_0_0_1_0-27:\thyp=['YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n",
            "1_1_1_1_1_0_0_0-28:\tref=['YES', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n",
            "1_1_1_1_1_0_0_0-28:\thyp=['YES', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n",
            "1_1_1_1_1_1_1_1-29:\tref=['YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES']\n",
            "1_1_1_1_1_1_1_1-29:\thyp=['YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lQFBS-KdIVx",
        "outputId": "3b46b712-8042-4eeb-dd02-a0c7bf6a11b3"
      },
      "source": [
        "#8. show the detailed WER\n",
        "! cd /content/icefall/egs/yesno/ASR && \\\n",
        "  cat tdnn/exp/errs-test_set.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%WER = 0.42\n",
            "Errors: 0 insertions, 1 deletions, 0 substitutions, over 240 reference words (239 correct)\n",
            "Search below for sections starting with PER-UTT DETAILS:, SUBSTITUTIONS:, DELETIONS:, INSERTIONS:, PER-WORD STATS:\n",
            "\n",
            "PER-UTT DETAILS: corr or (ref->hyp)  \n",
            "0_0_0_1_0_0_0_1-0:\tNO NO NO YES NO NO NO YES\n",
            "0_0_1_0_0_0_1_0-1:\tNO NO YES NO NO NO YES NO\n",
            "0_0_1_0_0_1_1_1-2:\tNO NO YES NO NO YES YES YES\n",
            "0_0_1_0_1_0_0_1-3:\tNO NO YES NO YES NO NO YES\n",
            "0_0_1_1_0_0_0_1-4:\tNO NO YES YES NO NO NO YES\n",
            "0_0_1_1_0_1_1_0-5:\tNO NO YES YES NO YES YES NO\n",
            "0_0_1_1_1_0_0_0-6:\tNO NO YES YES YES NO NO NO\n",
            "0_0_1_1_1_1_0_0-7:\tNO NO YES YES YES YES NO NO\n",
            "0_1_0_0_0_1_0_0-8:\tNO YES NO NO NO YES NO NO\n",
            "0_1_0_0_1_0_1_0-9:\tNO YES NO NO YES NO YES NO\n",
            "0_1_0_1_0_0_0_0-10:\tNO YES NO YES NO NO NO (NO->*)\n",
            "0_1_0_1_1_1_0_0-11:\tNO YES NO YES YES YES NO NO\n",
            "0_1_1_0_0_1_1_1-12:\tNO YES YES NO NO YES YES YES\n",
            "0_1_1_1_0_0_1_0-13:\tNO YES YES YES NO NO YES NO\n",
            "0_1_1_1_1_0_1_0-14:\tNO YES YES YES YES NO YES NO\n",
            "1_0_0_0_0_0_0_0-15:\tYES NO NO NO NO NO NO NO\n",
            "1_0_0_0_0_0_1_1-16:\tYES NO NO NO NO NO YES YES\n",
            "1_0_0_1_0_1_1_1-17:\tYES NO NO YES NO YES YES YES\n",
            "1_0_1_1_0_1_1_1-18:\tYES NO YES YES NO YES YES YES\n",
            "1_0_1_1_1_1_0_1-19:\tYES NO YES YES YES YES NO YES\n",
            "1_1_0_0_0_1_1_1-20:\tYES YES NO NO NO YES YES YES\n",
            "1_1_0_0_1_0_1_1-21:\tYES YES NO NO YES NO YES YES\n",
            "1_1_0_1_0_1_0_0-22:\tYES YES NO YES NO YES NO NO\n",
            "1_1_0_1_1_0_0_1-23:\tYES YES NO YES YES NO NO YES\n",
            "1_1_0_1_1_1_1_0-24:\tYES YES NO YES YES YES YES NO\n",
            "1_1_1_0_0_1_0_1-25:\tYES YES YES NO NO YES NO YES\n",
            "1_1_1_0_1_0_1_0-26:\tYES YES YES NO YES NO YES NO\n",
            "1_1_1_1_0_0_1_0-27:\tYES YES YES YES NO NO YES NO\n",
            "1_1_1_1_1_0_0_0-28:\tYES YES YES YES YES NO NO NO\n",
            "1_1_1_1_1_1_1_1-29:\tYES YES YES YES YES YES YES YES\n",
            "\n",
            "SUBSTITUTIONS: count ref -> hyp\n",
            "\n",
            "DELETIONS: count ref\n",
            "1   NO\n",
            "\n",
            "INSERTIONS: count hyp\n",
            "\n",
            "PER-WORD STATS: word  corr tot_errs count_in_ref count_in_hyp\n",
            "NO   115 1 116 115\n",
            "YES   124 0 124 124\n"
          ]
        }
      ]
    }
  ]
}